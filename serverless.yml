service: onondaga-e911

frameworkVersion: ">=1.2.0 <2.0.0"

plugins:
  - serverless-python-requirements

package:
  exclude:
    - node_modules/**
    - __pycache__/**
    - README.md
    - package.json
    - package-lock.json
    - Pipfile
    - Pipfile.lock

provider:
  name: aws
  runtime: python3.6
  region: us-east-1
  environment:
    DYNAMODB_TABLE: ${self:service}-${opt:stage, self:provider.stage}
    # FIREHOSE_STREAM: ${self:service}-${opt:stage, self:provider.stage}
    # S3_BUCKET: ${self:service}-${opt:stage, self:provider.stage}
  iamRoleStatements:
    - Effect: Allow
      Action:
        - dynamodb:Query
        - dynamodb:Scan
        - dynamodb:GetItem
        - dynamodb:PutItem
        - dynamodb:UpdateItem
        - dynamodb:DeleteItem
        - dynamodb:DescribeTable
        - dynamodb:GetRecords
        - dynamodb:GetShardIterator
        - dynamodb:DescribeStream
        - dynamodb:ListStreams
      Resource: "arn:aws:dynamodb:${opt:region, self:provider.region}:*:table/${self:provider.environment.DYNAMODB_TABLE}"

functions:
  cron:
    handler: scraper.run
    events:
      - schedule: rate(1 minute)

resources:
  Resources:

    CronLogGroup:
      Type: AWS::Logs::LogGroup
      Properties:
        RetentionInDays: "7"

    DynamoDbTable:
      Type: 'AWS::DynamoDB::Table'
      DeletionPolicy: Retain
      Properties:
        TableName: ${self:provider.environment.DYNAMODB_TABLE}
        AttributeDefinitions:
          - AttributeName: date
            AttributeType: S
          - AttributeName: timestamp_hash
            AttributeType: S
        KeySchema:
          # NOTES: this creates one hot partition for each day's writes.
          #        this is bad practice for high scale
          - AttributeName: date # partition key
            KeyType: HASH
          - AttributeName: timestamp_hash # sort key
            KeyType: RANGE
        ProvisionedThroughput:
          ReadCapacityUnits: 1
          WriteCapacityUnits: 1
